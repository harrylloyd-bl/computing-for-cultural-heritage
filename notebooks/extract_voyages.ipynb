{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python #1 - Working with Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the June '25 Hack & Yack, part of the development of a new [Computing for Cultural Heritage](https://blogs.bl.uk/digital-scholarship/2021/09/computing-for-cultural-heritage-trial-outcomes-and-final-report.html). The aim of this programme, that we're currently seeking funding for, is to teach staff the fundamentals of programming in a cultural heritage context. In this session we'll introduce some fundamentals of the Python programming language by extracting structured information from unstructured text about voyages of ships in the India Office Records. If you get far enough with the session you'll clean some data for, and be credited on, a new dataset uploaded to the research repository!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This session had a small pre-work notebook to work through. This matches the planned format for the new course. The notebook covered using Jupyter notebooks (the format of this web page) and some basic Python data types. If you didn't have time to work through this before we recommend doing it now. It should take 15 minutes or so. If you've already finished it you might want to have it open as a handy reference for this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format:\n",
    "- Introduction (10 mins)\n",
    "- The task: extracting structured information from unstructured text data (5 mins)\n",
    "- Looking at the data (10 mins)\n",
    "- Defining our outputs (15 mins)\n",
    "- Break (5 mins)\n",
    "- Working through exercises (45 mins)\n",
    "- Debrief and processing data for the repository (30 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teachers\n",
    "- Harry Lloyd (host)\n",
    "- Jez Cope (online)\n",
    "\n",
    "If you have questions in the room I'll try and help you out, if you're online drop Jez a message!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covered in the pre-work (as well as today)\n",
    "- Writing and running python code in a JupyterLab notebook\n",
    "- Python variables and how to create them\n",
    "- Creating and interacting with Python data types and data structures\n",
    "    - String and integer data types\n",
    "    - Lists\n",
    "    - Dictionaries\n",
    "\n",
    "Covered in this notebook\n",
    "- Navigating the JupyterLab file system\n",
    "- How to convert your approach to solving a problem into code\n",
    "- The snake_case and PascalCase Naming conventions\n",
    "- How to iterate over lists of things using For loops\n",
    "- Using regular expressions to find matching strings of characters in text\n",
    "- How to import and export data from the filesystem\n",
    "- The basic structure of json as a data storage format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dljAL_g-8hjr"
   },
   "source": [
    "## Today's Task\n",
    "\n",
    "> Convert unstructured text data about the histories of East India Company ships into a structured format to provide easier to process data to readers.\n",
    "\n",
    "### The Dataset\n",
    "A file of ship authority records at `data\\raw\\clean_ship_sample.csv`, mostly based on entries from Anthony Farrington's *Catalogue of East India Company Ships' Journals and Logs*, which was keyed in the early 2000s and later imported to IAMS. The entries are formatted pretty consistently in the *Catalogue*, the consistency was replicated in the keying, which we'll take advantage of today. The raw dataset used to produce this sample is `data\\raw\\IAMS_pre_cyber_export_Corporation_authority.xlsx`, taken from `ACT_Metadata\\IAMS\\IAMS Oct 2023 authority listings`, filtered by Alex Hailey for a ship related subset of the CorporationAdditionalQualifiers column.\n",
    "\n",
    "We're using a subset of columns from the full files: RecordID, ShipName, DateRange, History."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dljAL_g-8hjr"
   },
   "source": [
    "<u>RecordID</u>  \n",
    "The IAMS Record ID for this Corporate Authority record.\n",
    "\n",
    "<u>ShipName</u>  \n",
    "The ship's name, unmodified from the CorporationCorporateName column in the raw IAMS dataset.\n",
    "\n",
    "<u>History</u>    \n",
    "Text about the history of the ship. Usually split into (1) information like contract type, size, builder, owner, and (2) details of voyages, which can be multiple. Voyages are numbered, and typically record the years of voyage with destination, captain (if known), and stops. Here's an example:\n",
    ">Chartered ship, 32/35 crew, 450 tons. Principal Managing Owner: William Bawtree. Voyages: (1) 1818/9 Bengal. Capt Lucas Percival. Downs 27 May 1819 - 30 Sep Bengal - 29 Dec Narsipur - 3 Jan 1820 Madras - 22 Mar St Helena - 13 May East India Dock. (2) 1822/3 Bengal. Capt Lucas Percival. Downs 25 May 1829 - 21 Sep Hugli - 14 Oct Calcutta - 29 Jan 1824 Saugor - 2 Apr St Helena - 17 Jun East India Dock.\n",
    "\n",
    "  \n",
    "<u>DateRange</u>  \n",
    "The range of years during which the ship was active. These are present for the sample, but most entries in the full dataset have individual start and end dates expressed as '-9999', and date ranges as 'Undetermined'. There's a separate project to update dates in the authority files. Processing the data below could produce information helpful in updating dates using the unique authority IDs, but we will focus on extracting voyage data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dljAL_g-8hjr"
   },
   "source": [
    "## What you need to do\n",
    "\n",
    "- \n",
    "- check your output against the answer using `show_mismatches`\n",
    "  \n",
    "Iterate over csv, create dictionary for each ship recording basic info (ship name, id, info), and extracting voyage data from free text 'history' column, with voyages recorded as list of lists containing tuples which record date and location. Individual ship dictionaries then added to a main dictionary, with ID as key.\n",
    "\n",
    "This one has basic error handling to record problem records and then continue running. (My first time using try / except / else and it probably shows!)\n",
    "\n",
    "With a sample dataset of 97 records, 40 had to be passed. The full  dataset consists of c1500 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![book_cover](book_cover_voyage_text.png \"Book Cover of Farrington's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TEwcqfow8eZK"
   },
   "outputs": [],
   "source": [
    "# IMPORT STATEMENTS\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most basic workflow with sanitised data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No conditionals to check to make logic more flexible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also use this to find just the records that are parsable with the basic logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teaching_parse(ship_id, row, date_place_regex=\"default\", place_date_regex=\"default\"):\n",
    "    if date_place_regex == \"default\":\n",
    "        date_place_regex = re.compile(r\"(?P<Date>\\d{1,2} \\w{3}( \\d{4})?) (?P<Location>\\b[\\w\\s]*\\b)\")\n",
    "    if place_date_regex == \"default\":\n",
    "        place_date_regex = re.compile(r\"(?P<Location>\\b[\\w\\s]*\\b) (?P<Date>\\d{1,2} \\w{3} \\d{4})\")\n",
    "    \n",
    "    ship_info = {\n",
    "        \"name\": row[\"CorporateName\"],\n",
    "        \"dates\": row[\"DateRange\"],\n",
    "        \"info\": \"\",\n",
    "        \"voyages\": {},\n",
    "        \"raw_history\": row[\"History\"]\n",
    "    }\n",
    "\n",
    "    voyages = {}\n",
    "    info, voyage_string = row[\"History\"].split(\"Voyages: \")\n",
    "    ship_info[\"info\"] = info.strip()\n",
    "\n",
    "    voyage_numbers = re.findall(r\"(?<=\\()\\d{1,2}(?=\\))\", voyage_string)  # This finds any number in round brackets `(i)`, and keeps the number\n",
    "    raw_voyages = re.split(r\"\\(\\d{1,2}\\) \", voyage_string)[1:]  # First item in list is empty string due to split around first bracketed voyage number (1) \n",
    "    for i, rv in zip(voyage_numbers, raw_voyages):\n",
    "        voyage = {\n",
    "            \"voyage_number\": int(i),\n",
    "            \"duration\": \"\",\n",
    "            \"destination\": \"\",\n",
    "            \"captain\": \"\",\n",
    "            \"route\": []\n",
    "        }\n",
    "\n",
    "        duration_dest, captain, route_str = rv.split(\". \")[:3]\n",
    "        duration, destination = duration_dest.split(\" \")[:2]\n",
    "\n",
    "        voyage[\"captain\"] = captain\n",
    "        voyage[\"destination\"] = destination\n",
    "        voyage[\"duration\"] = duration\n",
    "\n",
    "        raw_stops = route_str.split(\" - \")\n",
    "        stops = []\n",
    "        \n",
    "        start = place_date_regex.search(raw_stops[0])\n",
    "        start_location, start_date = start.group(\"Location\"), start.group(\"Date\")\n",
    "        \n",
    "        stops.append({start_date: start_location})\n",
    "\n",
    "        for stop in raw_stops[1:]:\n",
    "            match = date_place_regex.search(stop)\n",
    "            loc, date = match.group(\"Location\"), match.group(\"Date\")\n",
    "            stops.append({date: loc})\n",
    "\n",
    "        voyage[\"route\"] = stops\n",
    "\n",
    "        voyages[int(i)] = voyage\n",
    "\n",
    "    ship_info[\"voyages\"] = voyages\n",
    "    \n",
    "    return ship_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_json(ships, f):\n",
    "    ship_dict = {}\n",
    "    for s in ships:\n",
    "        ship_dict |= s\n",
    "\n",
    "    with open(f, \"w\") as f:\n",
    "        json.dump(ship_dict, f, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_json(fp):\n",
    "    with open(fp, \"r\") as f:\n",
    "        ship_dict = json.load(f)\n",
    "\n",
    "    return [{k:v} for k,v in ship_dict.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying clean ships to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ships = []\n",
    "\n",
    "for ship_id, row in ships_df.iterrows():\n",
    "    try:\n",
    "        teaching_parse(ship_id, row)\n",
    "        clean_ships.append(ship_id)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_ships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ships_df.loc[pd.Index(clean_ships)].query(\"DateRange != 'Unspecified'\").iloc[:20].to_csv(\"../data/raw/ships_sample.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with the clean ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"../data/raw/clean_ships_sample.csv\", index_col=0, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_voyages = []\n",
    "\n",
    "for ship_id, row in sample_df.iterrows():\n",
    "    ship_info = teaching_parse(ship_id, row, date_place_regex=re.compile(r\"(?P<Date>\\d{1,2} \\w{3}( \\d{4})?) (?P<Location>\\b[\\w\\s']*\\b)\"))\n",
    "    ship_voyages.append({ship_id: ship_info})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_json(ship_voyages, \"../data/processed/ships_1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'045-001114649': {'name': 'Boscawen',\n",
       "  'dates': '1748-1765',\n",
       "  'info': 'Rated at 499 tons, 26 guns, 99 crew. Principal Managing Owner: 4 Richard Crabb.',\n",
       "  'voyages': {1: {'voyage_number': 1,\n",
       "    'duration': '1748/9',\n",
       "    'destination': 'Bombay',\n",
       "    'captain': 'Capt Benjamin Braund',\n",
       "    'route': [{'26 Mar 1749': 'Downs'},\n",
       "     {'5 Jul': 'Johanna'},\n",
       "     {'2 Aug': 'Bombay'},\n",
       "     {'22 Sep': 'Surat'},\n",
       "     {'17 Nov': 'Bandar Abbas'},\n",
       "     {'23 Dec': 'Bombay'},\n",
       "     {'11 Feb 1750': 'Mangalore'},\n",
       "     {'17 Feb': 'Tellicherry'},\n",
       "     {'19 Mar': 'Socotra'},\n",
       "     {'29 Mar': 'Mokha'},\n",
       "     {'27 Aug': 'Bombay'},\n",
       "     {'16 Jan 1751': 'Cape'},\n",
       "     {'17 Feb': 'St Helena'},\n",
       "     {'4 Jun': 'Gravesend'}]},\n",
       "   2: {'voyage_number': 2,\n",
       "    'duration': '1752/3',\n",
       "    'destination': 'Madras',\n",
       "    'captain': 'Capt Benjamin Braund',\n",
       "    'route': [{'27 Dec 1752': 'Downs'},\n",
       "     {'15 Mar 1753': 'Cape'},\n",
       "     {'24 Jun': 'Madras'},\n",
       "     {'9 Sep': 'Whampoa'},\n",
       "     {'26 Dec': 'Second Bar'},\n",
       "     {'7 May': 'St Helena'},\n",
       "     {'22 Jul': 'Erith'}]},\n",
       "   3: {'voyage_number': 3,\n",
       "    'duration': '1756/7',\n",
       "    'destination': 'Madras,',\n",
       "    'captain': 'Capt Benjamin Braund',\n",
       "    'route': [{'30 Jan 1757': 'Downs'},\n",
       "     {'16 Jul': 'Madagascar'},\n",
       "     {'5 Sep': 'Madras'},\n",
       "     {'28 Nov': 'Balasore'},\n",
       "     {'20 Dec': 'Calcutta'},\n",
       "     {'29 Mar 1758': 'Ingeli'},\n",
       "     {'5 Jul': 'Madras'},\n",
       "     {'21 Oct': 'Whampoa 4 Feb 1759'},\n",
       "     {'15 May': 'off St Helena'},\n",
       "     {'7 Jun': 'San Salvador'},\n",
       "     {'27 Dec': 'Cork'},\n",
       "     {'2 Feb': 'Plymouth'},\n",
       "     {'27 Mar': 'Erith'}]},\n",
       "   4: {'voyage_number': 4,\n",
       "    'duration': '1760/1',\n",
       "    'destination': 'Bombay',\n",
       "    'captain': 'Capt Benjamin Braund',\n",
       "    'route': [{'26 May 1761': 'Portsmouth'},\n",
       "     {'16 Aug': 'Rio de Janeiro'},\n",
       "     {'16 Dec': 'Anjengo'},\n",
       "     {'25 Dec': 'Tellicherry'},\n",
       "     {'9 Jan 1762': 'Goa'},\n",
       "     {'19 Feb': 'Bombay'},\n",
       "     {'2 Mar': 'Surat'},\n",
       "     {'12 May': 'Mokha'},\n",
       "     {'14 Jun': 'Jeddah'},\n",
       "     {'22 Aug': 'Mokha'},\n",
       "     {'15 Sep': 'Surat'},\n",
       "     {'14 Oct': 'Bombay'},\n",
       "     {'19 Nov': 'Cannanore'},\n",
       "     {'22 Nov': 'Calicut'},\n",
       "     {'25 Nov': 'Cochin'},\n",
       "     {'30 Nov': 'Anjengo'},\n",
       "     {'1 Feb 1763': 'Kedgeree'},\n",
       "     {'1 Apr': 'Ingeli'},\n",
       "     {'8 Jun': 'Calcutta'},\n",
       "     {'10 Feb 1764': 'Culpee'},\n",
       "     {'9 Mar': 'Barrabulla'},\n",
       "     {'26 Jun': 'Mauritius'},\n",
       "     {'29 Dec': 'Bourbon'},\n",
       "     {'21 Jan 1765': 'Cape'},\n",
       "     {'27 Feb': 'St Helena'},\n",
       "     {'31 May': 'Blackwall'}]}},\n",
       "  'raw_history': 'Rated at 499 tons, 26 guns, 99 crew. Principal Managing Owner: 4 Richard Crabb. Voyages: (1) 1748/9 Bombay. Capt Benjamin Braund. Downs 26 Mar 1749 - 5 Jul Johanna - 2 Aug Bombay - 22 Sep Surat - 17 Nov Bandar Abbas - 23 Dec Bombay - 11 Feb 1750 Mangalore - 17 Feb Tellicherry - 19 Mar Socotra - 29 Mar Mokha - 27 Aug Bombay - 16 Jan 1751 Cape - 17 Feb St Helena - 4 Jun Gravesend. (2) 1752/3 Madras and China. Capt Benjamin Braund. Downs 27 Dec 1752 - 15 Mar 1753 Cape - 24 Jun Madras - 9 Sep Whampoa - 26 Dec Second Bar - 7 May St Helena - 22 Jul Erith. (3) 1756/7 Madras, Bengal and China. Capt Benjamin Braund. Downs 30 Jan 1757 - 16 Jul Madagascar - 5 Sep Madras - 28 Nov Balasore - 20 Dec Calcutta - 29 Mar 1758 Ingeli - 5 Jul Madras - 21 Oct Whampoa 4 Feb 1759 - 15 May off St Helena, unable to call because of French ships - 7 Jun San Salvador - 27 Dec Cork - 2 Feb Plymouth - 27 Mar Erith. (4) 1760/1 Bombay and Bengal. Capt Benjamin Braund. Portsmouth 26 May 1761 - 16 Aug Rio de Janeiro - 16 Dec Anjengo - 25 Dec Tellicherry - 9 Jan 1762 Goa - 19 Feb Bombay - 2 Mar Surat - 12 May Mokha - 14 Jun Jeddah - 22 Aug Mokha - 15 Sep Surat - 14 Oct Bombay - 19 Nov Cannanore - 22 Nov Calicut - 25 Nov Cochin - 30 Nov Anjengo - 1 Feb 1763 Kedgeree - 1 Apr Ingeli - 8 Jun Calcutta - 10 Feb 1764 Culpee - 9 Mar Barrabulla - 26 Jun Mauritius - 29 Dec Bourbon - 21 Jan 1765 Cape - 27 Feb St Helena - 31 May Blackwall.'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ship_voyages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mismatches(s1: list[dict], s2: list[dict]):\n",
    "    s1_dict = {}\n",
    "    s2_dict = {}\n",
    "\n",
    "    for ship_id in s1:\n",
    "        s1_dict |= ship_id\n",
    "    for ship_id in s2:\n",
    "        s2_dict |= ship_id\n",
    "    if s1_dict == s2_dict:\n",
    "        print(\"Ships are identical\")\n",
    "        return None\n",
    "\n",
    "    s1_only = s1_dict.keys() - s2_dict.keys()\n",
    "    if s1_only:\n",
    "        print(f\"Ship IDs only present in first set: {'\\n'.join(s1_only)}\")\n",
    "    s2_only = s2_dict.keys() - s2_dict.keys()\n",
    "    if s2_only:\n",
    "        print(f\"Ship IDs only present in second set: {'\\n'.join(s2_only)}\")\n",
    "\n",
    "    print(\"Differences in information for Ship IDs present in both sets:\")\n",
    "    common_ship_ids = s1_dict.keys() & s2_dict.keys()\n",
    "    for ship_id in common_ship_ids:  # TODO refactor to check if value is dict/list then recur/use repeatable fn to compare, rather than these nested lists\n",
    "        s1_ship_info = s1_dict[ship_id]\n",
    "        s2_ship_info = s2_dict[ship_id]\n",
    "\n",
    "        if s1_ship_info == s2_ship_info:\n",
    "            continue\n",
    "\n",
    "        if s1_ship_info.keys() ^ s2_ship_info.keys():\n",
    "            print(f\"{ship_id} has keys {', '.join(s1_ship_info.keys())} in set 1 and {', '.join(s2_ship_info.keys())} in set 2\")\n",
    "            print(f\"The differing keys are {s1_ship_info.keys() ^ s2_ship_info.keys()}\")\n",
    "\n",
    "        common_ship_info = s1_ship_info.keys() & s2_ship_info.keys()\n",
    "        for ship_key in common_ship_info:\n",
    "            s1_value, s2_value = s1_ship_info[ship_key], s2_ship_info[ship_key]\n",
    "            if ship_key != \"voyages\" and (s1_value != s2_value):\n",
    "                print(f\"Ship {ship_id} has {ship_key}: {s1_value} in set 1 and {ship_key}: {s2_value} in set 2\")\n",
    "\n",
    "            elif ship_key == \"voyages\" and (s1_value != s2_value):\n",
    "                s1_voyages, s2_voyages = s1_value, s2_value\n",
    "                print(f\"\\n**Ship {ship_id}**\")\n",
    "                if s1_voyages.keys() ^ s2_voyages.keys():\n",
    "                    print(\n",
    "                        f\"{ship_id} has voyages {', '.join(s1_voyages.keys())} in set 1 and {', '.join(s2_voyages.keys())} in set 2\")\n",
    "                    print(f\"The differing voyages are {s1_voyages.keys() ^ s2_voyages.keys()}\")\n",
    "\n",
    "                common_voyages = sorted(list(s1_voyages.keys() & s2_voyages.keys()))\n",
    "                for voyage_id in common_voyages:\n",
    "                    v1, v2 = s1_voyages[voyage_id], s2_voyages[voyage_id]\n",
    "                    if v1 != v2:\n",
    "                        print(f\"\\nVoyage {voyage_id}\")\n",
    "                        if v1.keys() ^ v2.keys():\n",
    "                            print(f\"{voyage_id} has keys {', '.join(v1.keys())} in set 1 and {', '.join(v2.keys())} in set 2\")\n",
    "                            print(f\"The differing keys are {v1.keys() ^ v2.keys()}\")\n",
    "\n",
    "                        common_voyage_info = v1.keys() & v2.keys()\n",
    "                        for v_key in common_voyage_info:\n",
    "                            v1_value, v2_value = v1[v_key], v2[v_key]\n",
    "                            if v_key != \"route\" and (v1_value != v2_value):\n",
    "                                print(f\"Voyage {voyage_id} has {v_key}: {v1_value} in set 1 and {v_key}: {v2_value} in set 2\")\n",
    "\n",
    "                            elif v_key == \"route\" and (v1_value != v2_value):\n",
    "                                s1_stops, s2_stops = v1_value, v2_value\n",
    "                                for stop in s1_stops:\n",
    "                                    if stop not in s2_stops:\n",
    "                                        print(f\"Stop {stop} in set 1 but not in set 2\\n\")\n",
    "                                for stop in s2_stops:\n",
    "                                    if stop not in s1_stops:\n",
    "                                        print(f\"Stop {stop} in set 2 but not in set 1\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2 = from_json(\"../data/processed/ships_0.json\"), from_json(\"../data/processed/ships_1.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences in information for Ship IDs present in both sets:\n",
      "\n",
      "**Ship 045-001114707**\n",
      "\n",
      "Voyage 1\n",
      "Stop {'6 Jan 1715': 'Cox'} in set 1 but not in set 2\n",
      "\n",
      "Stop {'6 Jan 1715': \"Cox's Island\"} in set 2 but not in set 1\n",
      "\n",
      "\n",
      "Voyage 2\n",
      "Stop {'29 Jan 1718': 'Cox'} in set 1 but not in set 2\n",
      "\n",
      "Stop {'29 Jan 1718': \"Cox's Island\"} in set 2 but not in set 1\n",
      "\n",
      "\n",
      "**Ship 045-001114683**\n",
      "\n",
      "Voyage 1\n",
      "Stop {'16 Jul': 'St Augustine'} in set 1 but not in set 2\n",
      "\n",
      "Stop {'16 Jul': \"St Augustine's Bay\"} in set 2 but not in set 1\n",
      "\n",
      "\n",
      "**Ship 045-001114757**\n",
      "\n",
      "Voyage 1\n",
      "Stop {'8 Jan': '1763'} in set 1 but not in set 2\n",
      "\n",
      "Stop {'8 Jan': \"1763 'Scindy Road\"} in set 2 but not in set 1\n",
      "\n",
      "\n",
      "**Ship 045-001114938**\n",
      "\n",
      "Voyage 3\n",
      "Stop {'17 Aug': 'St Augustine'} in set 1 but not in set 2\n",
      "\n",
      "Stop {'17 Aug': \"St Augustine's Bay\"} in set 2 but not in set 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_mismatches(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the live data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete data set is much messier. I've extended the logic of the algorithm for processing text data to handle the messiness. You can read it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ships_df = pd.read_csv(\"../data/raw/ships.csv\", index_col=\"RecordID\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(ships_df),50):\n",
    "    ships_df.iloc[i:i+50].to_csv(f\"../data/interim/extension/ships_subset_{int(i/50)}.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_date_regex = re.compile(r\"(?P<Location>[a-zA-Z\\s']*\\b)? ?(?P<Date>(\\d{1,2}\\s)?\\w{3}(\\s\\d{4})?)?\")\n",
    "date_place_regex = re.compile(r\"(?P<Date>(\\d{1,2}\\s)?\\w{3}(\\s\\d{4})?)? ?(?P<Location>\\b[a-zA-Z\\s'-]*\\b)\")\n",
    "duration_dest_regex = re.compile(r\"(?P<Duration>\\b[\\d/-]*\\b) ?(?P<Destination>[\\s\\w,&--'\\(\\)]*)?.?$\")\n",
    "\n",
    "ship_voyages = []\n",
    "voyage_part_parse_failures = []\n",
    "dur_date_failures = []\n",
    "date_place_failures = []\n",
    "place_date_failures = []\n",
    "\n",
    "for ship_id, row in ships_df.iterrows():\n",
    "    ship_info = {\n",
    "        \"name\": row[\"CorporateName\"],\n",
    "        \"dates\": row[\"DateRange\"],\n",
    "        \"info\": \"\",\n",
    "        \"voyages\": [],\n",
    "        \"raw_history\": row[\"History\"]\n",
    "    }\n",
    "\n",
    "    voyages = []\n",
    "    if type(row[\"History\"]) != str:\n",
    "        ship_info[\"info\"] = \"No history recorded\"\n",
    "        ship_voyages.append({ship_id: ship_info})\n",
    "        continue\n",
    "\n",
    "    if \"Voyages: \" in row[\"History\"]:\n",
    "        info, voyage_string = row[\"History\"].split(\"Voyages: \")\n",
    "        ship_info[\"info\"] = info.strip()\n",
    "    else:  # No voyage information\n",
    "        ship_info[\"info\"] = row[\"History\"]\n",
    "        ship_voyages.append({ship_id: ship_info})\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    raw_voyages = [x.strip() for x in re.split(r\"\\(\\d{1,2}\\) \", voyage_string) if x]  # First item in list is empty string due to split around first bracketed voyage number (1) \n",
    "    for rv in raw_voyages:\n",
    "        voyage = {\n",
    "            \"duration\": \"\",\n",
    "            \"start_date\": \"\",\n",
    "            \"end_date\": \"\",\n",
    "            \"destination\": \"\",\n",
    "            \"captain\": \"\",\n",
    "            \"route\": [],\n",
    "            \"parse_failure\": False\n",
    "        }\n",
    "\n",
    "        voyage_parts = [x.strip() for x in rv.split(\".\") if x]           \n",
    "        try:\n",
    "            if (\"Capt\" in rv or \"Master\" in rv) and \"-\" in rv:\n",
    "                duration_dest, captain, route_str = voyage_parts[:3]\n",
    "            elif (\"Capt\" in rv or \"Master\" in rv) and \"-\" not in rv:\n",
    "                duration_dest, capt = voyage_parts[:2]\n",
    "            elif \"-\" in rv:\n",
    "                duration_dest, route_str = voyage_parts[:2]\n",
    "            elif len(voyage_parts) == 2 and \"-\" not in rv:\n",
    "                duration_dest, route_str = voyage_parts\n",
    "            elif \"-\" not in rv:\n",
    "                duration_dest = rv\n",
    "        except ValueError:\n",
    "            voyage_part_parse_failures.append((ship_id, rv))\n",
    "            voyage[\"route\"].append(rv)\n",
    "            voyage[\"parse_failure\"] = True\n",
    "            voyages.append(voyage)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            dd_match = duration_dest_regex.match(duration_dest)\n",
    "            duration, destination = dd_match.group(\"Duration\"), dd_match.group(\"Destination\")\n",
    "        except AttributeError as e:\n",
    "            dur_date_failures.append((ship_id, duration_dest))\n",
    "            voyage[\"route\"].append(rv)\n",
    "            voyage[\"parse_failure\"] = True\n",
    "            voyages.append(voyage)\n",
    "            continue\n",
    "\n",
    "        voyage[\"captain\"] = captain\n",
    "        voyage[\"duration\"] = duration\n",
    "        voyage[\"destination\"] = destination\n",
    "\n",
    "        raw_stops = route_str.split(\" - \")\n",
    "        stops = []\n",
    "\n",
    "        try:\n",
    "            start = place_date_regex.search(raw_stops[0])\n",
    "            start_location, start_date = start.group(\"Location\"), start.group(\"Date\")\n",
    "            if start_location:\n",
    "                start_location = start_location.strip()\n",
    "        except AttributeError:\n",
    "            stops.append({\"Unparsed stop\": stop})\n",
    "            voyage[\"parse_failure\"] = True\n",
    "            place_date_failures.append((ship_id, raw_stops[0]))\n",
    "            \n",
    "        voyage[\"start_date\"] = start_date\n",
    "        \n",
    "        stops.append({start_date: start_location})\n",
    "\n",
    "        for stop in raw_stops[1:]:\n",
    "            dp_match = date_place_regex.match(stop)\n",
    "            if dp_match:\n",
    "                loc, date = dp_match.group(\"Location\").strip(), dp_match.group(\"Date\")\n",
    "                stops.append({date: loc})\n",
    "            elif not date and re.search(r\"\\d\", stop):  # Check if it's actually place/date format\n",
    "                pd_match = place_date_regex.match(stop)\n",
    "                pd_loc, pd_date = pd_match.group(\"Location\").strip(), pd_match.group(\"Date\")\n",
    "                if pd_date:\n",
    "                    loc, date = pd_loc, pd_date\n",
    "                    stops.append({date: loc})\n",
    "                else:\n",
    "                    date_place_failures.append((ship_id, stop))\n",
    "                    stops.append({\"unable_to_date\": stop})\n",
    "                    voyage[\"parse_failure\"] = True                       \n",
    "            else:\n",
    "                date_place_failures.append((ship_id, stop))\n",
    "                stops.append({\"unable_to_date\": stop})\n",
    "                voyage[\"parse_failure\"] = True    \n",
    "\n",
    "        if len(voyage_parts) > 3:\n",
    "            [stops.append({\"Additional voyage\": p}) for p in voyage_parts[3:]]\n",
    "            \n",
    "        voyage[\"route\"] = stops\n",
    "        voyage[\"end_date\"] = [x for x in stops[-1].keys()][0]\n",
    "\n",
    "        voyages.append(voyage)\n",
    "\n",
    "    ship_info[\"voyages\"] = voyages\n",
    "\n",
    "    ship_voyages.append({ship_id: ship_info})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ship_voyages), len(voyage_part_parse_failures), len(dur_date_failures), len(date_place_failures), len(place_date_failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ships_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ships_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_place_failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the inconsistencies in the voyage data that needs parsing if doing it using code.\n",
    "\n",
    "Types of `History` string:\n",
    " - Ship info and voyage info. Start with ship info then `Voyages:` and voyage info\n",
    " - Only voyage info, string starts with `Voyages:` and has voyage info only\n",
    "\n",
    "The voyages part is typically individual voyages in short text separated by voyage numbers in round brackets e.g. (1)\n",
    "Types of individual voyage string:\n",
    "- Years duration and a destination, then a captain, then text describing the stops on the voyage.\n",
    "Types of voyage string inconsistency:\n",
    "- No captain, just duration/destination then stops\n",
    "- No stops, just duration/destination then captain\n",
    "- No destination, just duration then captain/stops\n",
    "- No captain or stops\n",
    "- Poorly formatted: misplaced `.`, `-`\n",
    "- Journey variation: wrecked, didn't return\n",
    "\n",
    "At current all 'voyage_part_parse_failures' are due to missing '.' between parts of the voyage.\n",
    "\n",
    "The duration/destination can also vary:\n",
    "- Unhandled characters in the duration/destination text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Alex's questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1Cn86xVBi8f"
   },
   "source": [
    "#Next steps proposals / questions\n",
    "\n",
    "Run over the entire dataset. Take the IDs of problematic records and remove from dataset, then re-run on that to get an initial output and a set of problematic records for further examination.\n",
    "\n",
    "Examine initial output:\n",
    "\n",
    "*   Close reading to flag any errors\n",
    "*   Write code to flag voyage lists with len < 3\n",
    "*   Write code to flag voyage steps which look like this ('23 Sep', '1685.')\n",
    "*   Subsequent data cleaning / refining code\n",
    "\n",
    "\n",
    "Problem entries:\n",
    "\n",
    "*   Close reading to see what the problems might be and how to approach\n",
    "*   Possibly use a more granular approach. Split by '-' then look more closely?\n",
    "*   Run against gazatteer or use NER to identify place names and find closest dates?\n",
    "\n",
    "Other questions:\n",
    "\n",
    "*  Are nested dictionaries the best way of structuring this output? Would JSON be better?\n",
    "\n",
    "*  Ultimately I would like to take the voyage steps, geolocate the places and tidy the dates so that they can be queried (which ships pass place X within timespan Y) and plotted, although there's a lot of data cleaning to do before then.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Can I just use an LLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, and they can produce good results. The reason I haven't suggested them at the start is because this tutorial is about how to write Python, not how to prompt an LLM. Using LLMs for work tasks also raises a range of ethical considerations. Read the BL's AI Principles and explore a framework like the Library of Congress' Labs [AI Planning Framework](https://libraryofcongress.github.io/labs-ai-framework/) to help you understand the benefits and risks of carrying out this work at scale.\n",
    "\n",
    "Let's explore using an LLM as extra credit now you've done the bulk of your learning. LLMs are quite good at extracting structured data from unstructured text [references]. At the time of writing my impression is that Anthropic have the best governance processes, so open https://claude.ai and sign up for an account (~1 min). Then you can start putting in sections of the text and trying to get Claude to extract the data in a format similar to that above. Finding the right prompt is important, and is one of the skills needed to fruitfully interact with language models. Experiment yourself or make use of the one below, which I've adapted from [Matt Miller](https://thisismattmiller.com/post/using-gpt-on-library-collections/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "You are a helpful assistant that is extracting data from ship voyage information. You only answer using the text given to you. You do not make-up additional information, the answer has to be contained in the text provided to you. Each voyage is a string of text. \n",
    "You will structure your answer in valid JSON, extract the date in the format yyyy-mm-dd and the location the ship visited using the JSON keys dateVisited and location.\n",
    "\n",
    "If the following text contains multiple voyages, extract each one into an array of \n",
    "valid JSON dictionaries. Each dictionary represents one of the entries:\n",
    "\n",
    "Downs 27 May 1819 - 30 Sep Bengal - 29 Dec Narsipur - 3 Jan 1820 Madras - 22 Mar St Helena - 13 May East India Dock\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:cfch]",
   "language": "python",
   "name": "conda-env-cfch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
